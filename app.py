import streamlit as st
import torch
import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from transformers import GPT2Tokenizer
import joblib
import torch
# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load the trained SVM model
model_path = "/Users/salomonmuhirwa/Downloads/llm-detect-ai-generated-text(1)/svm_model.pth"  # Update with the path to your trained model file
model = torch.load(model_path)

# Load GPT-2 tokenizer
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

# Define stopwords for NLTK tokenizer
stop_words = set(stopwords.words('english'))

# Initialize NLTK tokenizer
tokenizer_nltk = RegexpTokenizer(r'\w+')

# Function to process text
def process_text(text):
    max_chunk_length = 128  # Adjust this value as needed
    text_chunks = [text[i:i + max_chunk_length] for i in range(0, len(text), max_chunk_length)]
    outputs = []
    for chunk in text_chunks:
        # Tokenize using NLTK tokenizer
        tokenized_text = tokenizer_nltk.tokenize(chunk.lower())
        # Remove stopwords
        tokenized_text = [word for word in tokenized_text if word not in stop_words]
        # Truncate or pad the sequence to match max_chunk_length
        tokenized_text = tokenized_text[:max_chunk_length] + ['<pad>'] * (max_chunk_length - len(tokenized_text))
        # Convert tokens to token IDs using GPT-2 tokenizer
        inputs = tokenizer.convert_tokens_to_ids(tokenized_text)
        # Convert token IDs to tensor
        inputs = torch.tensor(inputs).unsqueeze(0)
        outputs.append(inputs)
    return outputs

# Function to classify text
def classify_text(text):
    # Process text
    inputs = process_text(text)
    # Combine outputs from all chunks
    all_outputs = torch.cat(inputs, dim=0)
    # Predict
    predictions = model.predict(all_outputs.cpu().numpy())
    return predictions

# Streamlit app
def main():
    st.title("AI vs Human Text Detection")
    st.write("Enter text below to classify whether it was generated by AI or human.")

    # Text input
    text_input = st.text_area("Enter text here:")

    if st.button("Classify"):
        if text_input.strip() != "":
            # Classify text
            predictions = classify_text(text_input)
            if 1 in predictions:
                st.write("AI generated text")
            else:
                st.write("Human generated text")
        else:
            st.write("Please enter some text.")

if __name__ == "__main__":
    main()
